{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DAT19 Class 5 - Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation with KNN\n",
    "\n",
    "Part of the big step with this lab is understanding general sklearn syntax. Each family of classification algorithms have various knobs and levers to tune it appropriately but there is a general overall structure to these models that will help you as you move forward.\n",
    "1. All models need to be trained. Sklearn models have a `.fit` method for doing so.\n",
    "2. We need to use the model to make a guess. the `.predict` method takes data and returns the model's guess for the value. Stipulations around this pertain to the specific model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, we imported our data from the UCI Machine Learning repository using pandas. Scikit-learn also includes some well-known datasets. So, for convenience, we will import the iris data set from sklearn this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from the datasets load the iris data into a variable called iris\n",
    "from sklearn import datasets\n",
    "\n",
    "sk_iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.datasets.base.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sk_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target_names': array(['setosa', 'versicolor', 'virginica'], \n",
      "      dtype='|S10'), 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
      "       [ 4.9,  3. ,  1.4,  0.2],\n",
      "       [ 4.7,  3.2,  1.3,  0.2],\n",
      "       [ 4.6,  3.1,  1.5,  0.2],\n",
      "       [ 5. ,  3.6,  1.4,  0.2],\n",
      "       [ 5.4,  3.9,  1.7,  0.4],\n",
      "       [ 4.6,  3.4,  1.4,  0.3],\n",
      "       [ 5. ,  3.4,  1.5,  0.2],\n",
      "       [ 4.4,  2.9,  1.4,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 5.4,  3.7,  1.5,  0.2],\n",
      "       [ 4.8,  3.4,  1.6,  0.2],\n",
      "       [ 4.8,  3. ,  1.4,  0.1],\n",
      "       [ 4.3,  3. ,  1.1,  0.1],\n",
      "       [ 5.8,  4. ,  1.2,  0.2],\n",
      "       [ 5.7,  4.4,  1.5,  0.4],\n",
      "       [ 5.4,  3.9,  1.3,  0.4],\n",
      "       [ 5.1,  3.5,  1.4,  0.3],\n",
      "       [ 5.7,  3.8,  1.7,  0.3],\n",
      "       [ 5.1,  3.8,  1.5,  0.3],\n",
      "       [ 5.4,  3.4,  1.7,  0.2],\n",
      "       [ 5.1,  3.7,  1.5,  0.4],\n",
      "       [ 4.6,  3.6,  1. ,  0.2],\n",
      "       [ 5.1,  3.3,  1.7,  0.5],\n",
      "       [ 4.8,  3.4,  1.9,  0.2],\n",
      "       [ 5. ,  3. ,  1.6,  0.2],\n",
      "       [ 5. ,  3.4,  1.6,  0.4],\n",
      "       [ 5.2,  3.5,  1.5,  0.2],\n",
      "       [ 5.2,  3.4,  1.4,  0.2],\n",
      "       [ 4.7,  3.2,  1.6,  0.2],\n",
      "       [ 4.8,  3.1,  1.6,  0.2],\n",
      "       [ 5.4,  3.4,  1.5,  0.4],\n",
      "       [ 5.2,  4.1,  1.5,  0.1],\n",
      "       [ 5.5,  4.2,  1.4,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 5. ,  3.2,  1.2,  0.2],\n",
      "       [ 5.5,  3.5,  1.3,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 4.4,  3. ,  1.3,  0.2],\n",
      "       [ 5.1,  3.4,  1.5,  0.2],\n",
      "       [ 5. ,  3.5,  1.3,  0.3],\n",
      "       [ 4.5,  2.3,  1.3,  0.3],\n",
      "       [ 4.4,  3.2,  1.3,  0.2],\n",
      "       [ 5. ,  3.5,  1.6,  0.6],\n",
      "       [ 5.1,  3.8,  1.9,  0.4],\n",
      "       [ 4.8,  3. ,  1.4,  0.3],\n",
      "       [ 5.1,  3.8,  1.6,  0.2],\n",
      "       [ 4.6,  3.2,  1.4,  0.2],\n",
      "       [ 5.3,  3.7,  1.5,  0.2],\n",
      "       [ 5. ,  3.3,  1.4,  0.2],\n",
      "       [ 7. ,  3.2,  4.7,  1.4],\n",
      "       [ 6.4,  3.2,  4.5,  1.5],\n",
      "       [ 6.9,  3.1,  4.9,  1.5],\n",
      "       [ 5.5,  2.3,  4. ,  1.3],\n",
      "       [ 6.5,  2.8,  4.6,  1.5],\n",
      "       [ 5.7,  2.8,  4.5,  1.3],\n",
      "       [ 6.3,  3.3,  4.7,  1.6],\n",
      "       [ 4.9,  2.4,  3.3,  1. ],\n",
      "       [ 6.6,  2.9,  4.6,  1.3],\n",
      "       [ 5.2,  2.7,  3.9,  1.4],\n",
      "       [ 5. ,  2. ,  3.5,  1. ],\n",
      "       [ 5.9,  3. ,  4.2,  1.5],\n",
      "       [ 6. ,  2.2,  4. ,  1. ],\n",
      "       [ 6.1,  2.9,  4.7,  1.4],\n",
      "       [ 5.6,  2.9,  3.6,  1.3],\n",
      "       [ 6.7,  3.1,  4.4,  1.4],\n",
      "       [ 5.6,  3. ,  4.5,  1.5],\n",
      "       [ 5.8,  2.7,  4.1,  1. ],\n",
      "       [ 6.2,  2.2,  4.5,  1.5],\n",
      "       [ 5.6,  2.5,  3.9,  1.1],\n",
      "       [ 5.9,  3.2,  4.8,  1.8],\n",
      "       [ 6.1,  2.8,  4. ,  1.3],\n",
      "       [ 6.3,  2.5,  4.9,  1.5],\n",
      "       [ 6.1,  2.8,  4.7,  1.2],\n",
      "       [ 6.4,  2.9,  4.3,  1.3],\n",
      "       [ 6.6,  3. ,  4.4,  1.4],\n",
      "       [ 6.8,  2.8,  4.8,  1.4],\n",
      "       [ 6.7,  3. ,  5. ,  1.7],\n",
      "       [ 6. ,  2.9,  4.5,  1.5],\n",
      "       [ 5.7,  2.6,  3.5,  1. ],\n",
      "       [ 5.5,  2.4,  3.8,  1.1],\n",
      "       [ 5.5,  2.4,  3.7,  1. ],\n",
      "       [ 5.8,  2.7,  3.9,  1.2],\n",
      "       [ 6. ,  2.7,  5.1,  1.6],\n",
      "       [ 5.4,  3. ,  4.5,  1.5],\n",
      "       [ 6. ,  3.4,  4.5,  1.6],\n",
      "       [ 6.7,  3.1,  4.7,  1.5],\n",
      "       [ 6.3,  2.3,  4.4,  1.3],\n",
      "       [ 5.6,  3. ,  4.1,  1.3],\n",
      "       [ 5.5,  2.5,  4. ,  1.3],\n",
      "       [ 5.5,  2.6,  4.4,  1.2],\n",
      "       [ 6.1,  3. ,  4.6,  1.4],\n",
      "       [ 5.8,  2.6,  4. ,  1.2],\n",
      "       [ 5. ,  2.3,  3.3,  1. ],\n",
      "       [ 5.6,  2.7,  4.2,  1.3],\n",
      "       [ 5.7,  3. ,  4.2,  1.2],\n",
      "       [ 5.7,  2.9,  4.2,  1.3],\n",
      "       [ 6.2,  2.9,  4.3,  1.3],\n",
      "       [ 5.1,  2.5,  3. ,  1.1],\n",
      "       [ 5.7,  2.8,  4.1,  1.3],\n",
      "       [ 6.3,  3.3,  6. ,  2.5],\n",
      "       [ 5.8,  2.7,  5.1,  1.9],\n",
      "       [ 7.1,  3. ,  5.9,  2.1],\n",
      "       [ 6.3,  2.9,  5.6,  1.8],\n",
      "       [ 6.5,  3. ,  5.8,  2.2],\n",
      "       [ 7.6,  3. ,  6.6,  2.1],\n",
      "       [ 4.9,  2.5,  4.5,  1.7],\n",
      "       [ 7.3,  2.9,  6.3,  1.8],\n",
      "       [ 6.7,  2.5,  5.8,  1.8],\n",
      "       [ 7.2,  3.6,  6.1,  2.5],\n",
      "       [ 6.5,  3.2,  5.1,  2. ],\n",
      "       [ 6.4,  2.7,  5.3,  1.9],\n",
      "       [ 6.8,  3. ,  5.5,  2.1],\n",
      "       [ 5.7,  2.5,  5. ,  2. ],\n",
      "       [ 5.8,  2.8,  5.1,  2.4],\n",
      "       [ 6.4,  3.2,  5.3,  2.3],\n",
      "       [ 6.5,  3. ,  5.5,  1.8],\n",
      "       [ 7.7,  3.8,  6.7,  2.2],\n",
      "       [ 7.7,  2.6,  6.9,  2.3],\n",
      "       [ 6. ,  2.2,  5. ,  1.5],\n",
      "       [ 6.9,  3.2,  5.7,  2.3],\n",
      "       [ 5.6,  2.8,  4.9,  2. ],\n",
      "       [ 7.7,  2.8,  6.7,  2. ],\n",
      "       [ 6.3,  2.7,  4.9,  1.8],\n",
      "       [ 6.7,  3.3,  5.7,  2.1],\n",
      "       [ 7.2,  3.2,  6. ,  1.8],\n",
      "       [ 6.2,  2.8,  4.8,  1.8],\n",
      "       [ 6.1,  3. ,  4.9,  1.8],\n",
      "       [ 6.4,  2.8,  5.6,  2.1],\n",
      "       [ 7.2,  3. ,  5.8,  1.6],\n",
      "       [ 7.4,  2.8,  6.1,  1.9],\n",
      "       [ 7.9,  3.8,  6.4,  2. ],\n",
      "       [ 6.4,  2.8,  5.6,  2.2],\n",
      "       [ 6.3,  2.8,  5.1,  1.5],\n",
      "       [ 6.1,  2.6,  5.6,  1.4],\n",
      "       [ 7.7,  3. ,  6.1,  2.3],\n",
      "       [ 6.3,  3.4,  5.6,  2.4],\n",
      "       [ 6.4,  3.1,  5.5,  1.8],\n",
      "       [ 6. ,  3. ,  4.8,  1.8],\n",
      "       [ 6.9,  3.1,  5.4,  2.1],\n",
      "       [ 6.7,  3.1,  5.6,  2.4],\n",
      "       [ 6.9,  3.1,  5.1,  2.3],\n",
      "       [ 5.8,  2.7,  5.1,  1.9],\n",
      "       [ 6.8,  3.2,  5.9,  2.3],\n",
      "       [ 6.7,  3.3,  5.7,  2.5],\n",
      "       [ 6.7,  3. ,  5.2,  2.3],\n",
      "       [ 6.3,  2.5,  5. ,  1.9],\n",
      "       [ 6.5,  3. ,  5.2,  2. ],\n",
      "       [ 6.2,  3.4,  5.4,  2.3],\n",
      "       [ 5.9,  3. ,  5.1,  1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'DESCR': 'Iris Plants Database\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']}\n"
     ]
    }
   ],
   "source": [
    "print sk_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Bunch in module sklearn.datasets.base object:\n",
      "\n",
      "class Bunch(__builtin__.dict)\n",
      " |  Container object for datasets: dictionary-like object that\n",
      " |  exposes its keys as attributes.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Bunch\n",
      " |      __builtin__.dict\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from __builtin__.dict:\n",
      " |  \n",
      " |  __cmp__(...)\n",
      " |      x.__cmp__(y) <==> cmp(x,y)\n",
      " |  \n",
      " |  __contains__(...)\n",
      " |      D.__contains__(k) -> True if D has a key k, else False\n",
      " |  \n",
      " |  __delitem__(...)\n",
      " |      x.__delitem__(y) <==> del x[y]\n",
      " |  \n",
      " |  __eq__(...)\n",
      " |      x.__eq__(y) <==> x==y\n",
      " |  \n",
      " |  __ge__(...)\n",
      " |      x.__ge__(y) <==> x>=y\n",
      " |  \n",
      " |  __getattribute__(...)\n",
      " |      x.__getattribute__('name') <==> x.name\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __gt__(...)\n",
      " |      x.__gt__(y) <==> x>y\n",
      " |  \n",
      " |  __iter__(...)\n",
      " |      x.__iter__() <==> iter(x)\n",
      " |  \n",
      " |  __le__(...)\n",
      " |      x.__le__(y) <==> x<=y\n",
      " |  \n",
      " |  __len__(...)\n",
      " |      x.__len__() <==> len(x)\n",
      " |  \n",
      " |  __lt__(...)\n",
      " |      x.__lt__(y) <==> x<y\n",
      " |  \n",
      " |  __ne__(...)\n",
      " |      x.__ne__(y) <==> x!=y\n",
      " |  \n",
      " |  __repr__(...)\n",
      " |      x.__repr__() <==> repr(x)\n",
      " |  \n",
      " |  __setitem__(...)\n",
      " |      x.__setitem__(i, y) <==> x[i]=y\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      D.__sizeof__() -> size of D in memory, in bytes\n",
      " |  \n",
      " |  clear(...)\n",
      " |      D.clear() -> None.  Remove all items from D.\n",
      " |  \n",
      " |  copy(...)\n",
      " |      D.copy() -> a shallow copy of D\n",
      " |  \n",
      " |  fromkeys(...)\n",
      " |      dict.fromkeys(S[,v]) -> New dict with keys from S and values equal to v.\n",
      " |      v defaults to None.\n",
      " |  \n",
      " |  get(...)\n",
      " |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      " |  \n",
      " |  has_key(...)\n",
      " |      D.has_key(k) -> True if D has a key k, else False\n",
      " |  \n",
      " |  items(...)\n",
      " |      D.items() -> list of D's (key, value) pairs, as 2-tuples\n",
      " |  \n",
      " |  iteritems(...)\n",
      " |      D.iteritems() -> an iterator over the (key, value) items of D\n",
      " |  \n",
      " |  iterkeys(...)\n",
      " |      D.iterkeys() -> an iterator over the keys of D\n",
      " |  \n",
      " |  itervalues(...)\n",
      " |      D.itervalues() -> an iterator over the values of D\n",
      " |  \n",
      " |  keys(...)\n",
      " |      D.keys() -> list of D's keys\n",
      " |  \n",
      " |  pop(...)\n",
      " |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      " |      If key is not found, d is returned if given, otherwise KeyError is raised\n",
      " |  \n",
      " |  popitem(...)\n",
      " |      D.popitem() -> (k, v), remove and return some (key, value) pair as a\n",
      " |      2-tuple; but raise KeyError if D is empty.\n",
      " |  \n",
      " |  setdefault(...)\n",
      " |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      " |  \n",
      " |  update(...)\n",
      " |      D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\n",
      " |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
      " |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
      " |      In either case, this is followed by: for k in F: D[k] = F[k]\n",
      " |  \n",
      " |  values(...)\n",
      " |      D.values() -> list of D's values\n",
      " |  \n",
      " |  viewitems(...)\n",
      " |      D.viewitems() -> a set-like object providing a view on D's items\n",
      " |  \n",
      " |  viewkeys(...)\n",
      " |      D.viewkeys() -> a set-like object providing a view on D's keys\n",
      " |  \n",
      " |  viewvalues(...)\n",
      " |      D.viewvalues() -> an object providing a view on D's values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from __builtin__.dict:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __new__ = <built-in method __new__ of type object>\n",
      " |      T.__new__(S, ...) -> a new object with type S, a subtype of T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sk_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's interesting:\n",
    "```Container object for datasets: dictionary-like object that exposes its keys as attributes.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print sk_iris['DESCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_iris['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], \n",
       "      dtype='|S10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_iris['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Remember last time when we put all the features in a matrix and the labels (what we are trying to predict) into a vector?\n",
    "\n",
    "Let's re-assign the data to standard named variables. Sklearn makes this very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = sk_iris.data\n",
    "y = sk_iris.target\n",
    "Names = sk_iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(150, 4)\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]]\n"
     ]
    }
   ],
   "source": [
    "print type(X)\n",
    "print np.shape(X)\n",
    "print X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(3,)\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print type(Names)\n",
    "print np.shape(Names)\n",
    "print Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we get into cross validation! The first step is to split the data into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# is there a function to do that in sklearn?\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = range(150) #What data structure is ind? What is its shape?\n",
    "np.random.shuffle(ind) #Why must we randomly shuffle the (indices for the) training data before splitting it?\n",
    "test_ind = ind[:150/5] #Would this work if 20% of the number of records were not an integer?\n",
    "train_ind = ind[150/5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 76, 107, 84, 59, 116, 27, 62, 143, 36, 146, 24, 7, 73, 86, 3, 38, 137, 64, 54, 8, 46, 43, 67, 117, 121, 148, 147, 65, 102]\n",
      "length of test index is 30\n",
      "\n",
      "\n",
      "[134, 34, 144, 32, 71, 94, 5, 85, 133, 40, 128, 90, 29, 97, 30, 123, 13, 88, 140, 50, 4, 115, 72, 39, 14, 77, 33, 95, 37, 19, 87, 93, 51, 110, 6, 26, 106, 98, 60, 138, 79, 141, 23, 42, 104, 142, 132, 113, 111, 124, 25, 99, 74, 136, 12, 149, 129, 68, 139, 75, 41, 17, 16, 20, 127, 21, 22, 11, 83, 49, 48, 120, 63, 0, 58, 82, 66, 28, 57, 81, 35, 31, 47, 78, 131, 119, 15, 96, 126, 122, 10, 1, 105, 118, 103, 80, 69, 112, 92, 108, 114, 70, 61, 55, 52, 135, 9, 101, 44, 130, 100, 53, 125, 109, 89, 2, 45, 91, 145, 18]\n",
      "length of training index is 120\n"
     ]
    }
   ],
   "source": [
    "print test_ind\n",
    "print 'length of test index is ' + str(len(test_ind))\n",
    "print '\\n'\n",
    "print train_ind\n",
    "print 'length of training index is ' + str(len(train_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for ind in test_ind:\n",
    "    X_test.append(X[ind])\n",
    "    y_test.append(y[ind])\n",
    "    \n",
    "for ind in train_ind:\n",
    "    X_train.append(X[ind])\n",
    "    y_train.append(y[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a minute, what's going on with this syntax above? Does anything about it look unusual to you?\n",
    "Let's take a look at the [function documentation](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html) and the [user guide](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "<type 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 6.4,  3.1,  5.5,  1.8],\n",
       "        [ 5.4,  3. ,  4.5,  1.5],\n",
       "        [ 5.2,  3.5,  1.5,  0.2],\n",
       "        [ 6.1,  3. ,  4.9,  1.8],\n",
       "        [ 6.4,  2.8,  5.6,  2.2],\n",
       "        [ 5.2,  2.7,  3.9,  1.4],\n",
       "        [ 5.7,  3.8,  1.7,  0.3],\n",
       "        [ 6. ,  2.7,  5.1,  1.6],\n",
       "        [ 5.9,  3. ,  4.2,  1.5],\n",
       "        [ 5.8,  2.6,  4. ,  1.2],\n",
       "        [ 6.8,  3. ,  5.5,  2.1],\n",
       "        [ 4.7,  3.2,  1.3,  0.2],\n",
       "        [ 6.9,  3.1,  5.1,  2.3],\n",
       "        [ 5. ,  3.5,  1.6,  0.6],\n",
       "        [ 5.4,  3.7,  1.5,  0.2],\n",
       "        [ 5. ,  2. ,  3.5,  1. ],\n",
       "        [ 6.5,  3. ,  5.5,  1.8],\n",
       "        [ 6.7,  3.3,  5.7,  2.5],\n",
       "        [ 6. ,  2.2,  5. ,  1.5],\n",
       "        [ 6.7,  2.5,  5.8,  1.8],\n",
       "        [ 5.6,  2.5,  3.9,  1.1],\n",
       "        [ 7.7,  3. ,  6.1,  2.3],\n",
       "        [ 6.3,  3.3,  4.7,  1.6],\n",
       "        [ 5.5,  2.4,  3.8,  1.1],\n",
       "        [ 6.3,  2.7,  4.9,  1.8],\n",
       "        [ 6.3,  2.8,  5.1,  1.5],\n",
       "        [ 4.9,  2.5,  4.5,  1.7],\n",
       "        [ 6.3,  2.5,  5. ,  1.9],\n",
       "        [ 7. ,  3.2,  4.7,  1.4],\n",
       "        [ 6.5,  3. ,  5.2,  2. ],\n",
       "        [ 6. ,  3.4,  4.5,  1.6],\n",
       "        [ 4.8,  3.1,  1.6,  0.2],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 5.6,  2.7,  4.2,  1.3],\n",
       "        [ 5.6,  2.9,  3.6,  1.3],\n",
       "        [ 5.5,  2.5,  4. ,  1.3],\n",
       "        [ 6.1,  3. ,  4.6,  1.4],\n",
       "        [ 7.2,  3.2,  6. ,  1.8],\n",
       "        [ 5.3,  3.7,  1.5,  0.2],\n",
       "        [ 4.3,  3. ,  1.1,  0.1],\n",
       "        [ 6.4,  2.7,  5.3,  1.9],\n",
       "        [ 5.7,  3. ,  4.2,  1.2],\n",
       "        [ 5.4,  3.4,  1.7,  0.2],\n",
       "        [ 5.7,  4.4,  1.5,  0.4],\n",
       "        [ 6.9,  3.1,  4.9,  1.5],\n",
       "        [ 4.6,  3.1,  1.5,  0.2],\n",
       "        [ 5.9,  3. ,  5.1,  1.8],\n",
       "        [ 5.1,  2.5,  3. ,  1.1],\n",
       "        [ 4.6,  3.4,  1.4,  0.3],\n",
       "        [ 6.2,  2.2,  4.5,  1.5],\n",
       "        [ 7.2,  3.6,  6.1,  2.5],\n",
       "        [ 5.7,  2.9,  4.2,  1.3],\n",
       "        [ 4.8,  3. ,  1.4,  0.1],\n",
       "        [ 7.1,  3. ,  5.9,  2.1],\n",
       "        [ 6.9,  3.2,  5.7,  2.3],\n",
       "        [ 6.5,  3. ,  5.8,  2.2],\n",
       "        [ 6.4,  2.8,  5.6,  2.1],\n",
       "        [ 5.1,  3.8,  1.6,  0.2],\n",
       "        [ 4.8,  3.4,  1.6,  0.2],\n",
       "        [ 6.5,  3.2,  5.1,  2. ],\n",
       "        [ 6.7,  3.3,  5.7,  2.1],\n",
       "        [ 4.5,  2.3,  1.3,  0.3],\n",
       "        [ 6.2,  3.4,  5.4,  2.3],\n",
       "        [ 4.9,  3. ,  1.4,  0.2],\n",
       "        [ 5.7,  2.5,  5. ,  2. ],\n",
       "        [ 6.9,  3.1,  5.4,  2.1],\n",
       "        [ 4.4,  3.2,  1.3,  0.2],\n",
       "        [ 5. ,  3.6,  1.4,  0.2],\n",
       "        [ 7.2,  3. ,  5.8,  1.6],\n",
       "        [ 5.1,  3.5,  1.4,  0.3],\n",
       "        [ 4.4,  3. ,  1.3,  0.2],\n",
       "        [ 5.4,  3.9,  1.7,  0.4],\n",
       "        [ 5.5,  2.3,  4. ,  1.3],\n",
       "        [ 6.8,  3.2,  5.9,  2.3],\n",
       "        [ 7.6,  3. ,  6.6,  2.1],\n",
       "        [ 5.1,  3.5,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5.2,  3.4,  1.4,  0.2],\n",
       "        [ 5.7,  2.8,  4.5,  1.3],\n",
       "        [ 6.6,  3. ,  4.4,  1.4],\n",
       "        [ 5. ,  3.2,  1.2,  0.2],\n",
       "        [ 5.1,  3.3,  1.7,  0.5],\n",
       "        [ 6.4,  2.9,  4.3,  1.3],\n",
       "        [ 5.4,  3.4,  1.5,  0.4],\n",
       "        [ 7.7,  2.6,  6.9,  2.3],\n",
       "        [ 4.9,  2.4,  3.3,  1. ],\n",
       "        [ 7.9,  3.8,  6.4,  2. ],\n",
       "        [ 6.7,  3.1,  4.4,  1.4],\n",
       "        [ 5.2,  4.1,  1.5,  0.1],\n",
       "        [ 6. ,  3. ,  4.8,  1.8],\n",
       "        [ 5.8,  4. ,  1.2,  0.2],\n",
       "        [ 7.7,  2.8,  6.7,  2. ],\n",
       "        [ 5.1,  3.8,  1.5,  0.3],\n",
       "        [ 4.7,  3.2,  1.6,  0.2],\n",
       "        [ 7.4,  2.8,  6.1,  1.9],\n",
       "        [ 5. ,  3.3,  1.4,  0.2],\n",
       "        [ 6.3,  3.4,  5.6,  2.4],\n",
       "        [ 5.7,  2.8,  4.1,  1.3],\n",
       "        [ 5.8,  2.7,  3.9,  1.2],\n",
       "        [ 5.7,  2.6,  3.5,  1. ],\n",
       "        [ 6.4,  3.2,  5.3,  2.3],\n",
       "        [ 6.7,  3. ,  5.2,  2.3],\n",
       "        [ 6.3,  2.5,  4.9,  1.5],\n",
       "        [ 6.7,  3. ,  5. ,  1.7],\n",
       "        [ 5. ,  3. ,  1.6,  0.2],\n",
       "        [ 5.5,  2.4,  3.7,  1. ],\n",
       "        [ 6.7,  3.1,  5.6,  2.4],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 5.1,  3.4,  1.5,  0.2],\n",
       "        [ 6.6,  2.9,  4.6,  1.3],\n",
       "        [ 5.6,  3. ,  4.1,  1.3],\n",
       "        [ 5.9,  3.2,  4.8,  1.8],\n",
       "        [ 6.3,  2.3,  4.4,  1.3],\n",
       "        [ 5.5,  3.5,  1.3,  0.2],\n",
       "        [ 5.1,  3.7,  1.5,  0.4],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 6.3,  2.9,  5.6,  1.8],\n",
       "        [ 5.8,  2.7,  4.1,  1. ],\n",
       "        [ 7.7,  3.8,  6.7,  2.2],\n",
       "        [ 4.6,  3.2,  1.4,  0.2]]), array([[ 5.8,  2.8,  5.1,  2.4],\n",
       "        [ 6. ,  2.2,  4. ,  1. ],\n",
       "        [ 5.5,  4.2,  1.4,  0.2],\n",
       "        [ 7.3,  2.9,  6.3,  1.8],\n",
       "        [ 5. ,  3.4,  1.5,  0.2],\n",
       "        [ 6.3,  3.3,  6. ,  2.5],\n",
       "        [ 5. ,  3.5,  1.3,  0.3],\n",
       "        [ 6.7,  3.1,  4.7,  1.5],\n",
       "        [ 6.8,  2.8,  4.8,  1.4],\n",
       "        [ 6.1,  2.8,  4. ,  1.3],\n",
       "        [ 6.1,  2.6,  5.6,  1.4],\n",
       "        [ 6.4,  3.2,  4.5,  1.5],\n",
       "        [ 6.1,  2.8,  4.7,  1.2],\n",
       "        [ 6.5,  2.8,  4.6,  1.5],\n",
       "        [ 6.1,  2.9,  4.7,  1.4],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 6. ,  2.9,  4.5,  1.5],\n",
       "        [ 5.5,  2.6,  4.4,  1.2],\n",
       "        [ 4.8,  3. ,  1.4,  0.3],\n",
       "        [ 5.4,  3.9,  1.3,  0.4],\n",
       "        [ 5.6,  2.8,  4.9,  2. ],\n",
       "        [ 5.6,  3. ,  4.5,  1.5],\n",
       "        [ 4.8,  3.4,  1.9,  0.2],\n",
       "        [ 4.4,  2.9,  1.4,  0.2],\n",
       "        [ 6.2,  2.8,  4.8,  1.8],\n",
       "        [ 4.6,  3.6,  1. ,  0.2],\n",
       "        [ 5.1,  3.8,  1.9,  0.4],\n",
       "        [ 6.2,  2.9,  4.3,  1.3],\n",
       "        [ 5. ,  2.3,  3.3,  1. ],\n",
       "        [ 5. ,  3.4,  1.6,  0.4]]), array([2, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 2, 1,\n",
       "        1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0, 0, 1, 0,\n",
       "        2, 1, 0, 1, 2, 1, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2,\n",
       "        0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2,\n",
       "        0, 0, 2, 0, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 2, 1, 2, 0]), array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0,\n",
       "        0, 2, 0, 0, 1, 1, 0])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts_return = train_test_split( X, y, test_size=0.20, random_state=0)\n",
    "print len(tts_return)\n",
    "print type(tts_return)\n",
    "tts_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5.9,  3. ,  5.1,  1.8],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 2, 1,\n",
       "       1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0, 0, 1, 0,\n",
       "       2, 1, 0, 1, 2, 1, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2,\n",
       "       0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2,\n",
       "       0, 0, 2, 0, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0,\n",
       "       0, 2, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick Question: How can we double check that got the number of features and labels that we expected?\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll train our model and use it to make predictions, following the steps we outlined last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train KNN classifier defined function on the train data\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myknn = KNeighborsClassifier(2).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's figure out how good our model is. The traditional score is what percentage of my labels did I correctly identify. This is called **accuracy** or **precision**. There are other types of statistical scores but we will start here. We'll ask our model to predict what the labels for our test set are, then generate a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0,\n",
       "       0, 2, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = myknn.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number correct: 29\n",
      "Score: 0.966666666667\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for a,b in zip(y_test,myknn.predict(X_test)):\n",
    "    if a == b:\n",
    "        correct += 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print \"Number correct:\",correct\n",
    "print \"Score:\",float(correct)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was easy enough. Sklearn also has an easy method for generating a score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myknn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn also has a way of showing more information about the prediction. Here, we're using sklearn.metrics.classification_report to generate a more informative picture. The wikipedia pages for recall, f1-score, and support are also informative if you're looking to understand more.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        11\n",
      " versicolor       0.93      1.00      0.96        13\n",
      "  virginica       1.00      0.83      0.91         6\n",
      "\n",
      "avg / total       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print metrics.classification_report([sk_iris['target_names'][label] for label in y_test], \n",
    "                                    [sk_iris['target_names'][label] for label in myknn.predict(X_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "#### 1. How does the model perform as we increase the number of neighbors?  To answer this, plot the score as a function of the number of neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x107441410>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAH7CAYAAACJ/ji0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xm4ZFV5qPG36aYnmm4a6Kbp02g74BIccAoOMYkhRolJ\nWcYbRSISJRqSSDQ+pSbR64BejXqtCEa90aAxOIFjyjIiamJwQhMUEAVWRCVwqhuaZugBuunp3D/2\nLqkuzlDD3rXrVL2/56nn1LD3qnVqn1P11bfW+vaCqakpJEmSNBwOKboDkiRJuo/BmSRJ0hAxOJMk\nSRoiBmeSJElDxOBMkiRpiBicSZIkDRGDM0nTCiG8MIRwaYfbvjiE8K1ZHv+PEMIfZ9c7SRpdi4ru\ngKS5hRBuBJYBD4ox3pPe91LghTHG35xhn48CZwJPjDH+V3rfQ4H/jjHO+cUsxvgJ4BNZ9B+YSi+5\nCCEcAO5Jn2MbcDHwmhjjgbyes18hhKcBH4sxHpdD2w8Cfgb8Q4zxz7NuX1K+zJxJ88chwCu73OcO\n4P/k0JdChBBm+0L56Bjj4cBvAX8IvCzDtofOHP09E/gxcFoIYfGAugRACMHPFalP8+rNSBpjU8C7\ngdeGED4QY9zW4T7/DPxhCOHXY4zfbN8ghLAK+Dvgd4ADwD8Bb4oxHgghvBj44xjjr6XbPgP4e+AY\nkozaI4ELY4wfbmnv/wJ/DNwF/HmM8SstT/fQEML3gYcD3wBeEmO8M93v2cDfAuuBq4A/izFenz52\nI/AB4Azg+BDCYbNlxGKMMR1ifUQI4cHABcCj09fjUuDlzddvmrZXAK8BXgqsBW4GXh9j/Jd0+xeT\nBH3fB14C3E4SCAXgXGAJScbuwnT7JcDbgOelj30BeBWwELgEWBxC2JH27WHArcBfpc9/BPBvwJ/G\nGO8MIWwEfp4+9ibgF8DT2n//EMIC4EXAa4F3ACXgcy2Pl9O+Pgi4LX09Lg0hHAlUgWeQZGkvizH+\nfvvfQdrGAeChMcafpxnaXcADgV8Hnh1CWEbypeDBJJnMD8cYz23Z/6nAu4ATgB3AG4BrgTpwbIxx\nKt3uucAbY4yPaf89pVHmNxxp/rgC+A/g1V3scw/wdpIAYTofBfYADwEeS/LB/NL2jUIIRwOfIQkc\njgQi8GQOHqp8InA9cBTJB++HWx5bQBLEvAQ4FtgHvDdt+2HAJ4FXAEcDXwbqbZmhF5AEkEfMEpgt\nSNs7Efg14Mr0vrelz3kCcBzw5rb9WtveD9wAPDXGuJIkiPl4COGYlu1PBq5OX4dPAZ8GHkfyGp4B\nvC+EsDzd9h3AQ4GT0p8TJMHG3cCpwKYY4+ExxpUxxlvS1+DZJEHOscCdwPvb+vvrJAHuM2d4HZ5K\nEkB/meSY/VHzgRDCySQBeyXGuCpt68b04Y8BS4ETSQLTv5uh/emcDrw1xrgC+A6wEzgjfY7fBf4s\nDQoJITww7dv5JMf7McCV6dD77W2/14vS/kpjxcyZNH9MAW8EvhNCOL+LfT4IvDqEcCpJ4AFAGnA0\ng5LdwK4QwnkkmaEPtbXzLODHzQwS8N4QQnuQ+D/NLFoI4ULgAyGEtTHGLWk/LowxXps+/gbgqhDC\nHwGnAV+KMf5b+ti7SYZvnwJ8M933vTHGxhy/6w9DCPtJhnL/EfhomoH5Wfr41hDCe0hew9bX56C2\nY4yfbbn+6RDC35AEnl9M7/5FjPGf075+Gng98JYY417gayGEPSRZwmvS1/LRMca70u3/liTr+DrS\nYLLN2cA5McZN6fbnAv8TQjijZZs3xxh3zfI6/BFQjzHuDiF8BnhNCOHoGONWkqzmh5uvdcvzHEsS\nLB7ZkpWdcYHHNP4lxnh52ua9wGXNB2KM14QQLgJ+A6iRDDl/LcZ4cbrJHekF4EKSAPcraSbvGcCf\ndtEPaSQYnEnzSIzxJyGELwF/DVzXvD+E8Drgb9KbH2udBB5j3BNCeCvwVpIsUdMDgUOBzSGE5n2H\nADdN89Trgcm2+9pv39LynPekba4AtqR339yy7U3pcx9NkiG6qWXfqRDCzSRZJqbZdyaPjTH+vPWO\nNAA9nySbdDjJ73dH2343t+1zJsnQ48b0rhUk2cCmW1uu70r7fFvbfSuANcBy4Actr+8CZh+x2Ah8\nIR02bNpHkgmbtr9tfV8G/AFJhpIY41Xp0O0LSV6HDcC/TrPrccAdHQ6Xt5ui7W8hhPBEkqzhI4DF\nJEO6n255roOOU4tPAD9JM4/PB74ZY7x1hm2lkWVwJs0/bwJ+SDI/CIAY49tJhi/bNbMzHyUZkvxf\nLY/dDNwLHNXBqsZNJHOXgF/Oa9rQZb8f0HZ9L8mcp03Ao9raPg5ozZT1utLz7cB+4JExxrtCCM8h\nmTfX6pdtp0NuHwJOAS5PA8Xm8Gi3tpIEaifGGDdP8/h0v9NNJHPxLm9/IJ1zNtN+Tb8PrAQ+GEL4\nQHrfESTZtPNJjvlDp9nvZuDIEMKqaQK0u0mCzGY/1s3y/E2fJBm2fmb65eA93Bfg3kQyNHw/McbJ\nEML3gOeSZNA+MN120qhzzpk0z8QYf0ZSKmKulZu/DChijPtIgrq/arlvM/BV4O9CCIeHEA4JITwk\nhPDr07T1ZeBRIYRyOhfs5UAnH9KtfTkjhHBCmhV5C/CZdNjxM8DvhhBOCSEcClSA3cB3u2h/JitI\ngovtIYQJksn+szmMJPjZChwSQngJycKHrqUB7z8C54UQ1gCEECbShRWQZOCOCiGsbNntH4C3hxAe\nkG6/Jl0s0ak/Ipnr90iSeW4nAb8KnBRCeGT62EvS1/qQtD8h/Vu4hGQo+ogQwqEtfwdXkyyuOCmE\nsJT7z9mbLnBdAdyZBmYnkwxlNn0SeHoI4XkhhEUhhKNCCCe1PH4hyd/pI4HPd/G7SyPD4Eyan95C\nks2YLYvSXlvsUyRZqtb7ziQZdrqWZLjvM9wXdP1y/3S+0vNIJvpvJZlcfwVJ5m2656Lt9hTJh+5H\ngc3pc74ibTuSZEn+niST9rtAKQ0oOzXT63AuyWT9bSQrAT83y7akc+KqwOUkw7SPBL7d9jyz/Z7t\n/opknt/3QgjbgK+RrMokXY36KeDnIYQ70ozU+SRz274aQtie9qM1yzTjc6XB5ynAeTHGLS2XHwJf\nAc5MJ92/BHgPyYra/+C+jOaLSLKZ15MEjs3j898kf29fJ1kI8i3uf2zb+/XnwFvS3+ENJF8mSNu7\niWQOY4VkAcCVJKtpmz6f9ukL6VxIaewsmJrKrS4kIYSPkLzRbokxPmqGbd5LMin5HuDFMcYr0/tP\nBc4jWXJ+QYzxnbl1VFJXQlLL6mbgD2OMl821vdSNEMJPgbNjjP9edF+kIuSdOfsnkhVA0wohPIuk\nVs7xwJ8A/y+9fyHwvnTfE4HTQwgn5NxXSbMIITwjHfJaQrLaEOB7RfZJoyetbTZlYKZxlmtwFmP8\nFkmdnpk8m7SGTYzx+8ARaWr/ZOCGGOON6fL0i4Bynn2VNKcnkwzRNYcen5OWTZAyEUL4D5JFAC8v\nuCtSoYperTnBwcvCJ9P71k9z/xMH2C9JbdIK7+fOuaHUoxjj04rugzQMig7OoLcl6vdTqtSm3vOq\n3+ChG47IormefP0//4fzL76Kyh8+jqc9PttzGb/34iv52n9OV35KUlZe8NuBF5768KK7IWk8zBj/\nFB2cNUjqGTVtIMmSHdp2/3Hcv+Dl/bzqPZf9r3q1XNjS6/MvvuqtwP+ufvKHb3ja44/L9GTTX/vP\nm75OckLn3yUpSjmSzv2TJ1/6pg9dPtNpaTRPzMPjeAxw4UVfi//8wlMf/uKiOzNEpsjoC7QK5XGc\nZ4oOzr4InANcFEJ4EnBXjPHWEMLtJCch3kiy9P80knO3zaXbophZ29D2M+u2t9ar5S/n0PZQqVfL\nXy26D+rffDqOpUptKUmpj6LfQyQp3wUBIYRPkRSSDCGEm0MIZ4UQzg4hnA0QY/wySY2fG0jO//fn\n6f37SIK2S0nqL10cY7xu2ic52MTcm+Rqou1nJkqVWrMa+1znFpTUg3q1vJuk5lbR7yGSlG/mLMY4\nZ7YrxnjODPdfQlKxuhtFf+vNK3O2kqRy+ZxDu5J6Ngk8pOhOSNLInCFgQTKaXvS33lwyZy3tmTmT\n8tMAVpQqtZVzbilJORqZ4OyIFUugwMxZqVI7nCTDBbCmVKktybD55u9l5kzKT/P/q+gMvKQxNzLB\n2VGrlgJMpPOzitCeLVufQ9tmzqT8NP+/is7ASxpzIxScLQNYCqwuqAvNN/T9bbez0Pwmb3Am5af5\n/2XmTFKhRig4W9q8WtQba/N5r8mhH81Az2FNKT/N/y8zZ5IKNULB2bLm1aLeWJvP+/0c+uGwppQ/\nhzWlIRZCeE4I4UAIIRTdl7yNTHB29BFDkzn7zxz6sQG4G9iWYZuSDuaCAGm4nQ58ic6K0vckhDAU\ncVHRZwjIzFErRz5z1qhXy1MZtinpYNuAezBzJg2dEMIK4InAr5MUqH9zCGEh8E7gmcAB4B9jjO8L\nIfwKcB5JfdDdwNOBPwAeH2P8i7S9LwHvijF+M4SwE/iHdLuXhxBOAUrAMuC7Mcaz030emm53NMlp\nFJ8PvAn4fIyxlm7zCZLC+V/s5/cdneBsODJnu4HrSRYFZNKPtCTHGu6byyYpB/VqeapUqU1i5kya\nUalS+7/A8zJu9jP1avk1c2xTBr4SY7wphHBbCOFxJMHaA4CTYowHQgirQwiLgYuA58cYf5AGdbtI\nzi/aqvX2cuB7McZXA4QQro0xvjW9fmEI4fdijF8CPgG8PcZYS59nIfBh4FVALYSwCngy8KLeX4rE\nUKTvsjAkc84m69XyfpLzgWbVj2ZJDuebSflrkH2dQkn9Ox34THr9M8AfAr8FfDDGeAAgxngnEIDN\nMcYfpPftjDHun6a9VvuBz7XcPiWE8L0Qwo+AU4ATQwiHA+ubGbIY454Y464Y4zdJzgV+dNrHzzb7\n04+RyZwtW7IIYDsFBGelSm0xsJYkawbJG/wTSpXaIfVqud+DZBkNaXCa/2frgV8U2RFpGKUZrrmy\nXJkKIRwJ/CbwyBDCFEnGaopkjnentU33cXBCamnL9d0xxqn0uZYC7ycZAm2EEN6UbjvbtKILSbJl\npwEv7rA/sxqZzFmqqCGJY0n+QJoTiidJAt+1GbRtGQ1pcCynIQ2fPwAujDFujDE+KMb4AJIvTz8C\nzk7nnhFCWA1E4NgQwhPS+w5PH78ReEwIYUEI4Tjg5Bmeqxm03Z4OiT4PkgwcMBlCKKftLgkhNIfs\nPgr8JTAVY7yeDIxacNYAVpcqteUDft72UhdZLsm3jIY0OJbTkIbPC4AvtN33OZLEyE3Aj0IIVwGn\nxxj3kGSw/j6971JgSYzxOyQB3bXA+cAPWtr6ZVYsxngX8I/Aj4GvcN8iP0iyY68IIVwNfAc4Jt1n\nS9ruP2Xy2zJCw5qp1m+9Px3g87YPPbZWGv/B/TfvqW0zZ1L+LKchDZkY4ynT3Pf3LTcrbY9dQTIx\nv32fM2Zof2Xb7TcAb5hmuxtI5rkdJISwHDge+NT0v0H3RjFzBoP/1ts+9Jjl0IiZM2lwzJxJ6lgI\n4ekkWbP3xhh3ZNXuqGbOBv2td7bMWRZt7wO2ZNCWpNmZOZPUsRjj14GNWbdr5iwbeWfONqclOiTl\nawvJsnozZ5IKM6rBWRGZswPArentTenPvt7gS5XaISRL+h3SlAYg/RK0GTNnkgo0asFZUcvgm9mt\nfQD1ank3sJX+3+DXkgw9uxhAGpxJYH365UiSBm7U3ny2AnsYYHA2S3arAWwoVWqdFsibjosBpMFr\nkHwpWlN0RySNp5EKztITgzcY7JDE0cBipg/ODgNW3m+PzllGQxo8FwVIKtRIBWepBrCuVKkNaiXq\nTBX8sxhiNXMmDZ7lNCQVahSDs0mS32vdgJ5vpnNfZvEGb+ZMGjwzZ5IKNYrB2aC/9c6VOevnDd7M\nmTR4Zs4kFWqUg7NBfesdROZs06xbScpSUSV5JAkYzeBs0OU08s6cbU1Lc0gaDDNnkgo1isFZUcOa\nmWbO0hIcG6ZpV1KO0i9Dt2PmTFJBRjE4G/Rk3g3AHfVqeVfb/duAu/vox0qSUhwuBpAGbxIzZ5IK\nMorB2WZgisFmzu6X3WqpudZrP1wMIBWnAawoVWr91CmUpJ6MXHBWr5b3kpzjMvfMWalSO5wkwzVT\nANUA1pQqtSU9NG8ZDak4ltOQVJiRC85SDWCiz1MndWKmxQC03b++j7bNnEmD56IASYUZ5eBsKXBk\nzs8zUxkN2u7v5Q1+rrYl5cdyGpIKM6rB2aDKaXSaOevlDX6utiXlZ9AleSTpl0Y1OBvUkMRcQ49m\nzqT5ycyZpMKManA2qMm8c03a7zdzdjdJSQ5Jg2XmTFJhRjU4G4XM2QTQSEtySBqsbcA9GJxJKsCo\nBmeDzJztBu6c4fEtwH66fINPS2+swflmUiHSL0WTOKwpqQCjGpwNMnM2OVN2q14t7yc5aXm3b/DN\n0hvON5OK00+dQknq2UgGZ/VqeSewnRy/9ZYqtcXAMcwdQDWA9aVKrZvX2gK0UvH6qVMoST0byeAs\nlfe58Y5teZ65+rEIWNtF2xaglYpnIVpJhRjl4KwBrC5Vastzar/TAKqXN3jLaEjFs5yGpEKMcnCW\n91L4Tocee1mcYAFaqXiW05BUiFEOzvIeksgzc+awplQ8M2eSCjHKwVne5TQ6HXrsdVhzH0kpDknF\nMHMmqRCjHJwNKnOW17Dm5rQUh6Ri9FSnUJL6NQ7BWZ6ZswPArXNstyn92dEbfFpyYz3ON5MK1Ued\nQknqyygHZ3kPSTSzW/tm26heLe8GttL5G/xaktIbzjeTitdLnUJJ6ssov+FsBfaQQ3DWkt3qNIBq\ndNEPy2hIw6NB93UKJakvIxucpadUapDPkMTRwGI6H3qcBFaUKrWVHWxrGQ1peLgoQNLAjWxwlmoA\n60qV2qKM2+221EU3898soyEND8tpSBq4UQ/OJkl+x3UZt9vt0GM3K0c9r6Y0PMycSRq4UQ/O8iqn\n0e3QYzflNMycScPD82tKGrhxCc6yHpIYROZs06xbSRqEvItZS9L9jHpwlteQRN6Zs61pCQ5Jxeqq\nTqEkZWHUg7O8hzUzzZyVKrUFJAGcQ5rSEEi/JN2OmTNJA5T1KsaDhBBOBc4DFgIXxBjf2fb4auAj\nwIOB3cBZMcafpI/9DXAGSRX+a4CXxBjv7bILeQ1JbADuqFfLuzrcfhtwN3MHiSuBw3AxgDRMJoGH\nliq1BWmJHknKVW6ZsxDCQuB9wKnAicDpIYQT2jZ7HfDDGONJwJnA+em+G4GXAY+LMT6KJLh7QQ/d\n2AxMkU/mrOPsVhc111wMIA2fBsmXpk7qFEpS3/Ic1jwZuCHGeGOMcS9wEVBu2+YE4BsAMcYIbAwh\nrAG2A3uB5SGERcByeghY6tXyXpJzX2aWOStVaoeTvEl3m92aBNaUKrUls2xjGQ1p+FhOQ9JA5Rmc\nTQA3t9ye5P5vblcDzwUIIZwMPBDYEGO8A6gCN5FMyL0rxvj1HvvRACbS+VxZ6DW71dx+fQ5tS8qP\n5TQkDVSewVknczPeARwRQrgSOAe4EtgfQngI8JfARpJgZkUI4YUdPudBlyc+Yt3jgaWfeMvvHJju\n8W4vbz37ydcBnP6M8NJu9vuDU45/EcA7Xv7Un8+0zQtPffhHAM79kyd/OIu+ztPLtMfRy7y7jMxx\nfMXzH3MuwCtPe8xXi+6Lx9GLx3GkLjPKMzhrAMe13D6OtuG6GOOOGONZMcbHxhjPBNYAPweeAHw3\nxnh7jHEf8HngKR0854L2y/d/cssHAF74xktOmu7xbi9v+ODlLwb41Ffjy7rZ77P//tNzAP76/d8+\nfaZtPvGV6z8I8KYPXf7ILPo6Ty/THkcv8+4yMsfxvZ++6lSA8y++6g1F98Xj6MXjOFKXGeUZnF0B\nHB9C2BhCWAycBnyxdYMQwqr0MUIILwMuizHuBCLwpBDCshDCAuDpwLU99iPrIYl+hzVn60e3xW0l\n5c/za0oaqNyCszTjdQ5wKUlgdXGM8boQwtkhhLPTzU4ErgkhXA88E3hluu9VwIUkAd6P0m0/1GNX\nsi6n0euk/U4mFU+QlNzY1m2nJOXGBQGSBirXOmcxxkuAS9ru+2DL9cuBMMO+7wLelUE3hi1zNluQ\nuAFoWEtJGirbgHswcyZpQEb9DAGQT+ZsF3Bnl/ttAfYxQ5CYltg4GstoSEMl/bI03WpzScrFOARn\neWTOus5u1avl/SRFcWcKEpslNpxvJg2fBnPXKZSkTIx8cFavlneSDEv0nTkrVWqLgWPoPYBqAOtL\nldp0r7sFaKXh1fy/nK1OoSRlYuSDs1SDbDJnx6Y/ew2gJknm+a2d5jEL0ErDy0K0kgZmnIKz1aVK\nbXmf7fQbQM32Bm8ZDWl4WU5D0sCMS3CW1VL4foceZ+vHRNs2koaH5TQkDcy4BGdZDUlklTmb7tu3\nmTNpeJk5kzQw4xKcZVVOI+/M2T6SkhuShouZM0kDMy7B2XzInE0Am9OSG5KGyxZgP2bOJA3AuARn\nWWbODgC39rj/pvTnQUFiWlpjPc43k4ZS+qVpE2bOJA3AuARnWWbONter5X297FyvlncDW6fpx1qS\nEhvON5OG12x1CiUpM+PyJrMV2EMfwVlLdqvfAKrB/TN4LgaQhl+DmesUSlJmxiI4S0+1NF1Q1I2j\ngcX0P/Q4CawoVWorW+6zjIY0/FwUIGkgxiI4SzWAdaVKbVGP+2dVwX+6RQFmzqThZzkNSQMxTsHZ\nJMnvu67H/bM69+V0377NnEnDz8yZpIEYp+Cs30UBeWbOPK+mNPzMnEkaiHEKzvotp5Fn5qzZ9iYk\nDSszZ5IGYpyCs2HLnLUPa25NS21IGk7T1imUpKwZnHUul2HNUqW2IL3ukKY0xNIvT7fjsKaknI1T\ncJbFsOYd9Wp5V5/92AbczX3B3krgMFwMIM0Hk8CG9EuVJOVinIKzzcAU/WXO+s5uTVNzzTIa0vzR\nIPkytXKuDSWpV2MTnNWr5b0k58TsOnNWqtQOJ3kzziq7NQmsKVVqS7CMhjSfuChAUu7GJjhLNYCJ\nHoYksi510WxnfQ5tS8qP5TQk5W7cgrNJYClwZJf7ZVVGo7UfkARmWbctKT9mziTlbtyCs15XbOaV\nOZvIoW1J+TFzJil3BmedySs424ALAqT5pN+SPJI0p3ELznotp5HnsOYESWmNbRm1LSk/DmtKyt24\nBWfDmjlrpCU2JA23bcA9OKwpKUfjFpz1kznbBdyZUT+2APuAhwBH42IAaV5Iv0RNYuZMUo7GLTjr\nJ3OWWXarXi3vJymK++i2fkkafg3uq1MoSZkbq+CsXi3vJBmW6DhzVqrUFgPHkH12axJY1HJd0vzQ\n/H9dX2gvJI2ssQrOUg26y5wd27Jf1v2Y7rqk4WY5DUm5GtfgbHWpUlve4fZ51SEzOJPmJ8tpSMrV\nOAZn3S6Fz6uC/+QM1yUNN8tpSMrVOAZn3X7rNXMmqZXDmpJyNY7BWbflNPLOnO0jKa0haX4wcyYp\nV4vm3mTkNL/1Pr5Uqf24g+1PbNsv635sTktrSJoftgD7ySlzVqrU1pLfStDdQJxPRa9LldpS4NB6\ntbyj6L5IgzKOwdlN6c+/TC+d2AvcmnE/NpG8wf9Pxu1KylG9Wt5fqtQ2kUNwVqrUVgA/A1Zk3XaL\nFwEfz7H9rF0APLVUqT24Xi0fKLoz0iCMY3B2DfAauntj/X69Wt6XZSfq1fLuUqX2PODmLNuVNBAN\n4AmlSu2QjAOGB5EEZlcBl2XYLsBa4HTuK349X5wMPBBYQ/ZfkqWhNHbBWZrOf3fR/QCoV8tfKLoP\nknrSAJ5EEvDckmG7zXlsn61Xy2/LsF1KldoDSIKzeTNXrlSpLeC+/k5gcKYxMY4LAiSpX3ktCmhm\n9PNYwb0ZmGIeBWfAKqBZk9LVsRobBmeS1L28ymk0A6fMax/Wq+Xm3Nn5FOS09nU+BZVSXwzOJKl7\neWXO8qqr2NQAJtLhwvlgYobr0kgzOJOk7uWVOcurrmLTJLAUODKn9rO2YYbr0kgzOJOk7uWZOduR\nY02v+XZeUDNnGksGZ5LUvU3pzzwyZ3mea3e+nXrKzJnGksGZJHWpXi3vBm4nw2xOqVJbRjLcmOe5\ndufbqaea/byR+dNnqW8GZ5LUm0lgQ4aT6/NeDNDa9nwJdCaAncB1wOGlSm1lwf2RBsLgTJJ60wAO\nA7IKGHIro9Gi2fZ8GSJsDvPOt4yf1BeDM0nqTdYBg5mzFukJz48i6fO86beUBYMzSepN1pPr8y6j\nQb1a3glsY35kzlqD1fm2kEHqi8GZJPVmPmbOmu3PhwxU6zCvw5oaKwZnktSbeZc5SzWA1aVKbfmc\nWxar9TyjZs40VgzOJKk3Wc+DmgD2Alszam8m8yULZeZMY8vgTJJ6k3XAsAHYVK+WD2TU3kzmy+T6\n1mHeu4BdmDnTmFiUZ+MhhFOB84CFwAUxxne2Pb4a+AjwYGA3cFaM8SfpY0cAFwCPAKbSx76XZ38l\nqQvbgHvIIGAoVWoLgXXAIN7j5ks5jV8O89ar5alSpTbJ8AeUUiZyy5yFEBYC7wNOBU4ETg8hnNC2\n2euAH8YYTwLOBM5veex84MsxxhOAR5MUIZSkoVCvlqdIAp0sAoZjSL7E5r0YAOZX5mwvcFt6uwGs\nLVVqi4vrkjQYeQ5rngzcEGO8Mca4F7gIKLdtcwLwDYAYYwQ2hhDWhBBWAb8WY/xI+ti+GOO2HPsq\nSb1oAGtKldqSPtsZ1GIAmD+T6zcAm1uGeZv9Xl9Qf6SByXNYcwK4ueX2JPDEtm2uBp4LfDuEcDLw\nQJJ/yCngthDCPwEnAT8AXhljvCfH/kpSt5rB1HrgF320M6gyGjAPJtenw7zHAt9vubu13zcOuk/S\nIOWZOZvqYJt3AEeEEK4EzgGuBPaTBI2PAz4QY3wccDfw1x0+p5f5ffE4jsZlLI7jH5xy/IsA3vHy\np/68n3b+5DmP+jzAa1/0hGreff7iu5+9ZdHCQzj+uCN+f1iP40ff+Ix9wMJfPWn9U1peo78CeO0Z\nT/h20ccA47elAAAgAElEQVR9Hl4KOY5eOjou08ozOGsAx7XcPo62lH2McUeM8awY42NjjGcCa4Cf\np9tNxhj/K930syTB2lwWeJn3F4/jaFzG4jh+9t9/+hcAf/3+b5/eTzsf+pdr3gnwro9d8dS8+7xg\nwYIF+/Yf+MVPb75r07Aexxe/5asnA3zn6k3vaXmNngvwro9fUSn6uM/DSyHH0UtHx2VaeQZnVwDH\nhxA2hhAWA6cBX2zdIISwKn2MEMLLgMtijDtjjLcAN4cQHpZu+nTgJzn2VZJ6kdUQYWvB1UFoAOtK\nlVquK/b7MN0w73yZKyf1LbfgLMa4j2So8lLgWuDiGON1IYSzQwhnp5udCFwTQrgeeCbwypYm/gL4\nRAjhapLVmm/Pq6+S1KOsAoZmMLKpz3Y6NUny/r9uQM/XrekWSMyXVaZS33L91hRjvAS4pO2+D7Zc\nvxwIM+x7NfArefZPkvqUVeZsAthSr5b39NlOp1oDnUGsEO3WdJmzW0jmJBucaeR5hgBJ6t0WkoCh\n58xZqVJbkO4/yCBp2IcI75c5q1fL+0kCtGHts5QZgzNJ6lEaMGyiv2zOEcAyBjffDIa/nMZMw7yT\nwPpSpeZnl0aaf+CS1J8G/QUMgyxA2zQfMme3TTPM2wAOJVnZL40sgzNJ6k+DZP7u2h73H2QB2qah\nzZylw7wzzYUb2n5LWTI4k6T+9BswDLqMBsBmkiKYwxjkrAKWM/3rMewZPykTBmeS1J9+A4ZmgDSw\nYc16tbwXuJXhDHJmG+a1nIbGgsGZJPVnPmbOms83kQ4jDpPZhnkd1tRYMDiTpP7Mu8xZqgEsBY4c\n8PPOpZPM2TBm/KTMGJxJUn/6HWqbAHbUq+UdGfWnU8OahZotc+awpsaCwZkk9affgGHQBWibhjUL\nNeMwb71a3gXcwfD1WcqUwZkk9aFeLe8GbqeHgKFUqS0jGVYc9HwzGP7M2UwB6yTD12cpUwZnktS/\nSWBDD5Pri6hx1jSsQ4QTwM56tbx9hscbwOGlSm3lAPskDZTBmST1rwEcBnQbMBS1GACGe1hzttdj\nWINKKTMGZ5LUv16HCIsqo9H6nEMT5JQqtaXAUcz+egzrcKyUGYMzSepfr1mowjJn6erQ7QxX5qyT\n12NYM35SZgzOJKl/vWahipxzBsM3ub6T18PMmUaewZkk9a/fYc0i5pxBEgStLlVqywt6/nadDPOa\nOdPIMziTpP71M6y5F9iabXc6NmxZqG6GNYelz1LmDM4kqX/9ZM421avlAxn3p1PDFuh0Mqx5J7AL\nM2caYQZnktS/bcA9dBEwlCq1RcA6ihvShOEbIpxzmLdeLU+RnrR9ID2SCmBwJkl9SgOGbifXHwMs\npLjFADCcw5p7gdvm2G4SWFuq1Bbn3yVp8AzOJCkbDWBNqVJb0uH2RRagbRrGzFknw7zNfq/PuT9S\nIQzOJCkb3QYMRZfRgCHKnJUqtYXAsXT2egxNv6U8GJxJUja6DRiKLqMBySrRPQxH5qybYd5hy/hJ\nmTI4k6RsdBswFJ45G7LJ9d0M8w7bKlMpUwZnkpSNXjNnRQ5rNp9/Xbp6tEjdBKvN19rMmUaSwZkk\nZaPXzNmmHPrSjQbJZ8G6gvvRzTCvmTONNIMzScpGL5mzLfVqeU9O/enUsEyu7yZzdguwn+L7LOXC\n4EySsrGFJGCYM3NWqtQWkAQWRS4GaBqWyfUdZ87q1fJ+kgCt6D5LuTA4k6QMpAHDZjrL5hwBLKP4\n+WYwfJmzTod5J4H1pUrNzzGNHP+oJSk7nQYMw1BGo2mYMme3dTHM2wAOBdbk1yWpGAZnkpSdBrAI\nWDvHdoWX0WhR+OT6Hod5C++3lBeDM0nKTqdDhMNSRgOSodgpig1yVgHL6e71sJyGRpbBmSRlp9Mh\nwmE4ryYA6TDiFooNcnoZ5jVzppFlcCZJ2ZmPmTNI+j2RDi8WoZdh3mFZyCBlzuBMkrLTaTZnaDJn\nqQawFDiyoOfvJ3PmsKZGjsGZJGWn04BhA7CjXi3vyLk/nSo6C9VL5sxhTY0sgzNJyk43mbNhyZpB\n8YFO15nEerW8C7gDM2caQQZnkpSRerW8G7idWQKGUqW2jGT4cFjmm0HxQ4S9zsFrYOZMI8jgTJKy\nNQlsmGVy/TDVOGsahmHNnfVqeXuX+00Ch5cqtZU59EkqjMGZJGWrARwGzBQwDNtiABiOzFkvr0fR\nw7FSLgzOJClbc2Whhq2MBhQY5JQqtaXAUfT2ehSd8ZNyYXAmSdmaK9AZusxZump0O8Vkzvp5PYrO\n+Em5MDiTpGzNFTAMY+YM0kK0BTxvP3PwHNbUSDI4k6RszTXUNnSZs1QDWF2q1JYP+Hn7eT08v6ZG\nksGZJGVrrszZBLAX2DqY7nSsqCxUP5lEM2caSQZnkpStThYEbKpXywcG1J9OFTW5vp9hzTuBXZg5\n04gxOJOkbG0D7mGagKFUqS0C1jF8Q5pQ3OT6Xs6rCUC9Wp7CQrQaQQZnkpShOQKGY4CFDN9iACg2\nc7YXuK3H/SeBtaVKbXF2XZKKZXAmSdmbBNaUKrUlbfcP62IAKDZz1s8wb7Pf6zPqj1Q4gzNJyt5M\nAcOwltGAAibXlyq1hcCx9Pd6uChAI8fgTJKyN9MQ4TBnzrYCexhskLOWZJi3n9fDchoaOQZnkpS9\nmYYIh/Gk5wCkw4qbGGyQk0Um0cyZRo7BmSRlb6bM2TAPa0LS73XpqtJByCJYNXOmkWNwJknZmytz\ntmmAfelGg+RzYd2Anq/nMhotzJxp5OT67SiEcCpwHsmcggtijO9se3w18BHgwcBu4KwY409aHl8I\nXAFMxhhLefZVkjI0U8CwAdhSr5b3DLg/nWrN+A1iXlwWmbNbgP0YnGmE5JY5SwOr9wGnAicCp4cQ\nTmjb7HXAD2OMJwFnAue3Pf5K4FpgKq9+SlIObqUtYChVagsYXNDTq0GX0+g7c1avlveTBGgOa2pk\n5DmseTJwQ4zxxhjjXuAioNy2zQnANwBijBHYGEJYAxBC2AA8C7gAWJBjPyUpU2nAsJmDA4bVwDKG\nd74ZDH6IMKth3gawvlSpOVVHIyHPP+QJ4OaW25Pc/x/+auC5ACGEk4EHct+b2XuA1wDDdv45SerE\nJAcHDMNcRqNp0GcJmCCbYd5J4FBgTf9dkoqXZ3DWyVDkO4AjQghXAucAVwIHQgi/B2yJMV5Jd1mz\nKS/z/uJxHI3L2B/Hpzz62CcBiy580zP3A1NveumTfgRwxu88/M+K7ttMlw+//re/A/Abj93w2ryP\n49TU1NSSxQsf9uCJVWv7bev3nvqg5wK851W/cUvRr+GQXnI7jl76Pi7TyjM4awDHtdw+jrZvjDHG\nHTHGs2KMj40xnknyrefnwFOAZ4cQfgF8CjglhHBhB8+5wMu8v3gcR+My9sfxuz/afD7Amede+gRg\nwbkXfO9lAB+/5PoXF923mS5//LavLQGmLrty8rK8j+OzX/3F1ffu2c/PG9u+1G9bX/r2L/4K4FXv\nuaxc9Gs4pJfcjqOXvo/LtPIMzq4Ajg8hbAwhLAZOA77YukEIYVX6GCGElwGXpQHb62KMx8UYHwS8\nAPj3NHiTpPmiff7W0BagbUqHF7cwmMn1WZTRaLKchkZKbsFZjHEfyVDlpSQrLi+OMV4XQjg7hHB2\nutmJwDUhhOuBZ5KszpzOrOk/SRpC7Ssfh70AbdMkMJGuLs1TlsFqUSdtl3KRa52zGOMlwCVt932w\n5frlQJijjcuAy3LpoCTlp31y/XxYEABJoPN44MicnyfLzNmgFzJIuXLZsSTlY7rM2Y56tbyjoP50\nalBDhHlkzgzONBIMziQpH9PNORv2rBkMLguVWSaxXi3vAu7AYU2NCIMzScpBvVreDdwObChVastI\nhgmHfb4ZDG7+VtZz8BqYOdOIMDiTpPw0i2/Pl/lmMNjM2c56tbw9o/YmgcNLldrKjNqTCmNwJkn5\naQArSE5V17w97AaZOcsyWHXemUbGnMFZCGHdIDoiSSOoGTA8se32MMs9yClVakuBo8j29bCchkZG\nJ5mzb4UQ/jWE8LwQwqG590iSRkczM/TEtttDK11Nup18g5w8hnktp6GR0Ulw9jDgncCpwH+HEN4f\nQnhCvt2SpJHQzOac3HZ72OU9uT6PsyU4rKmRMWdwFmOcijF+k6Ta/5uBMvD5EMIPQghPzrl/kjSf\nNbM5K9tuD7tJYPXuPfvyaj/PzJnDmpr3Oplz9tshhH8Gfgb8GvD8GOMDgBcDn823e5I0r7VmhvYC\nW4vqSJcaAHds251X+3mcysrMmUZGJ8OabwS+ARwfY3xpjPG7ADHGa4B359k5SZrnWjNDjXq1fKCw\nnnRnEuD2/IKzPDJndwK7MHOmEdBJcPYsYEWM8e4QwkQI4a0hhOUAMcb35Ns9SZrXtgH3pNfny3wz\nSPu6dduuvNrPPHNWr5ansBCtRkQnwdkngWPT6zvSfT6WW48kaUS0BAwwD4OznDNne4HbMm63Aawt\nVWpLMm5XGqhOgrMHxhhfDxBj3J5ef2i+3ZKkkTHZ9nM+SIY178o1c7Yph2He5mt87KxbSUOuk+Ds\nQAjh0c0bIYQTgD35dUmSRsr8zZxtzz5zVqrUFpIET3m8Hi4K0EhY1ME2rwa+GkJo/tGvAc7Ir0uS\nNFLmY+ZsK7Bn6127FufQ9lpgIfm8Hs02v1Sq1HIbk51vVh++hDt33Lu56H506Q7g6fVqeb71OxNz\nBmcxxq+HEB4APIpkjkCMMd6be88kaTR8Gngc8O9Fd6RT9Wr5QKlS23T7tt0bc2g+jzIaTZcCPyQ5\nn6lSy5cuWnfnjnuzOsH8IBwBnAg8BfhcwX0pxJzBWQjh4cCfA4eRDIMuDCFsjDH+et6dk6T5rl4t\nXwk8s+h+9GDyrh27N5YqtUX1ajnLarR5lNEAoF4t/zfw+KzbHQFTQCi6E50qVWrPI/lSM7bD053M\nObuYpH7MY4ErSVLSl+TZKUlS4RoHpgBYl3G7eWbONBrG/mwPnQRnh8QY38R96eIy8/NboCSpc3lN\nrs/jvJoaLWO/sKOT4OzuEMIS4L+Bx6fzzY7Ot1uSpILllb1otjefFkhosDaTDMWaOZvFx4EvpZdX\nhBC+AmzKtVeSpKLlnTnzc0TTqlfLe4FbMXM2q28Bz40x3gY8DfgQ8Pt5dkqSVLhmZiuP4GxLvVq2\nXqZm0wAmSpXagqI7UoRO6pxdHGN8OECM8Wbg5ny7JEkaAs3MWWZDS+kH7QYgZtWmRtYkycrbI4Hb\nC+7LwHUSnP0khPBG4PvAL8/lEWP8Zm69kiQVbfOCBTA1lWnmbBWwHOebaW6tw+oGZ9M4CvjN9NKq\n/bYkaUTUq+U9L3rzV7hrx71ZTsq2jIY61Zq5/VGRHSlCJ2cIeNoA+iFJGjJHrVrKXTvunShVagvq\n1fJUBk1aRkOdymvO47zQyRkCvjHN3VMxxlNy6I8kaUgcvWoZP5vcthRYTXKuw35ZRkOdGutaZ50M\na57bcv1QkiK0d+bTHUnSsDhy1dLm1Q1kE5yZOVOnxvosAZ0Ma/5H211fCyH8J/CGXHokSRoKR69a\n1rw6QTbzfnI7r6ZGjpmz2YQQHtBycwHwSJKlrZKkEXbUwZmzLLggQB2pV8s7S5XaNsyczeibJKdR\nIP25FfiL3HokSRoKbZmzLEwAO+vV8vaM2tNoazCmmbM5zxAQY9wIPCzG+CDg4cApMcZL8u6YJKlY\nR+aTOXNIU51qAKtLldryojsyaHMGZyGE5wM/TG8+ALg+hPCcXHslSSpcy7Bm39mLUqW2lKRupkOa\n6tTYltPo5NyabwCeDhBjvAF4HAev4JQkjaDlSw8F2E42H44uBlC3xnZRQCfB2aExxlubN2KMW3Ls\njyRpuDTIZljTMhrq1tiW0+hkQcB3QgifAj5Bslrz+cDlufZKkjQsJoETSpXa8nq1fE8f7Zg5U7fM\nnM3i5SRzzs4GXgL8AHhFnp2SJA2NrD4gLaOhbo1t5qyjYU1gV4yxRBKUHUVnGTdJ0vyX1aRshzXV\nLTNns/gkcGx6fXu6z8dy65EkaZg0PyD7zV54Xk11ayuwB4OzaT0wxvh6gBjj9vT6Q/PtliRpSGSZ\nOdsL3NZnOxoT9Wp5iuwWpMwrnQRnB0IIj27eCCGcQBLJSpJGX5ZzzjbVq+UDfbaj8dIA1pUqtbGa\nTtXJL/tq4KshhOY/6NHAGfl1SZI0RPoe1ixVagtJpsd8P5MeaZxMkiSS1jFGQ+KdnL7p6yRnBvhT\noAZsBjx9kySNhyzm/RwDLGSMPlyVmbFcFNDJ6ZseDLwV+BLwepLA7ME590uSNATSYchN9Dfvx5Wa\n6lVWC1LmlRmDsxDCc0MIXyVJQx9JMpS5OcZ4rmcJkKSxMkl/834MztSrsTy/5mz/aJ9NL0+JMf4U\nIIQwNZBeSZKGSYP+5v1YRkO9GsthzdmCs0eTnBHgWyGEG4GL5thekjSaWrMXvQRYZs7Uq7E8S8CM\nw5oxxh/HGCskL8jfAk8Djgkh/GsI4XcH1D9JUvH6zV6YOVOvNgNTjFnmrJPVmvtijLUY43NI/sH+\njSRYkySNh34nZTc/WDdl0BeNkXq1vBe4FTNnM4sxbokx/l2M8dFzby1JGhH9TsreAGypV8sWMFcv\nGsBEqVJbUHRHBqWr4EySNJZ6zpylH6gTON9MvWsAS0kqR4wFgzNJ0lz6mfezCliOwZl6N3blNAzO\nJEmzSocjt9Dbh6OLAdSvsSunkXtpjBDCqcB5JKfuuCDG+M62x1cDHyE568Bu4KwY409CCMcBFwJr\nSb6xfSjG+N68+ytJmtYk8IhSpbagXi13U/PSMhrq19iV08g1cxZCWAi8DzgVOBE4PYRwQttmrwN+\nGGM8CTgTOD+9fy/wqhjjI4AnAS+fZl9J0mA05/2s7nI/M2fq19hlzvIe1jwZuCHGeGOMcS9JIdty\n2zYnAN8AiDFGYGMIYU2M8ZYY41Xp/TuB64D1OfdXkjS9XrMXZs7ULzNnGZsAbm65Pcn9I9+rgecC\nhBBOBh5I2wEIIWwEHktynk9J0uD1mr0wc6Z+jV3mLO85Z53MS3gHcH4I4UrgGuBKYH/zwRDCCpJz\nfL4yzaD1+3wafh7H0eBxHA1TAH/5gsdy3kVXcs7zTvpyNzs/4YRjuOK6W7n4bc+6Np/uqUPz9v+x\nXi1z2uv/lbWrl5/KPP49pjFj3ba8g7MGcFzL7eNo+/YUY9wBnNW8HUL4BfDz9PqhwOeAj8cY/6WD\n5xubAnUjbAqP4yjwOI6GXx7H8y668reAr7/vM1ef+8wnbXxzpw1ccd2tVwEPWb700MPz6aI6MO//\nH+/Zve8nN27efixjUuss72HNK4DjQwgbQwiLgdOAL7ZuEEJYlT5GCOFlwGUxxp0hhAXAh4FrY4zn\n5dxPSdLs+hnWdEhT/WoAq0uV2vKiOzIIuQZnMcZ9wDnApcC1wMUxxutCCGeHEM5ONzsRuCaEcD3w\nTOCV6f2/CpwB/GYI4cr0cmqe/ZUkzajrswSUKrWlwFG4GED9G6tCtLnXOYsxXgJc0nbfB1uuXw6E\nafb7NhbJlaShUK+Wd5Qqte109+HY3NbMmfrVmrn9aZEdGQSDH0lSpybprpyBZTSUlZ7P7zofGZxJ\nkjrV7bwfy2goK2M1rGlwJknqVLeLAsycKStjVevM4EyS1KlusxfNzJnBmfo1VmcJMDiTJHWq18yZ\nw5rq11ZgD2bOJEk6SLfZiwlgL3BbPt3RuKhXy1MkXw7MnEmS1KLbzNkGYFO9Wj6QU380XhrAulKl\nlnsZsKIZnEmSOtVx5qxUqS0EjsX5ZspOgyRuWVd0R/JmcCZJ6lQ3836OARbifDNlZ2zKaRicSZI6\n0uW8H8toKGtjU07D4EyS1I1O5/1YRkNZG5tyGgZnkqRuNOf9HDPHdpbRUNbMnEmSNI1OsxcOaypr\nZs4kSZpGp9kLz6uprG0GpjBzJknSQbrNnG3KsS8aI/VqeS+wBYMzSZIO0k3mbEu9Wt6Tc380XiaB\nDaVKbUHRHcmTwZkkqRtz1ppKPzgncL6ZstcAlgKri+5IngzOJEndaM77mW1Y8whgOQZnyt5YLAow\nOJMkdazDeT+W0VBexqKchsGZJKlbc837sYyG8tL8mzJzJklSi7nm/VhGQ3kZi/NrGpxJkro117wf\nM2fKi8OakiRNY64PSDNnyovDmpIkTWOuoSUzZ8pFvVreAWzHzJkkSQeZK3uxAdhZr5a3D6g/Gi+T\nmDmTJOkgcw1rTuCQpvLTAFaXKrXlRXckLwZnkqRuzZg5K1VqS4GjcEhT+Rn5RQEGZ5Kkrswx78cC\ntMrbyJfTMDiTJPVipnk/LgZQ3sycSZI0jea8n2Vt929oeVzKw8ifX9PgTJLUi5mGlhzWVN7MnEmS\nNI2ZFgWYOVPeRr4QrcGZJKkXZs5UlK3AHsycSZJ0kNkyZ3uB2wbbHY2LerV8ANiEwZkkSQeZad7P\nBLAp/QCV8jIJHFuq1BYV3ZE8GJxJknpxvxVzpUptIXAszjdT/hokMcwxRXckDwZnkqReTDfv5xhg\nIQZnyt9Il9MwOJMkda1eLU+RBGGtwZmLATQoI11Ow+BMktSrBgfP+7GMhgZlpMtpGJxJkno1ycHz\nfsycaVBG+vyaBmeSpF61Zy/MnGlQHNaUJGka7R+QZs40KJuBKRzWlCTpIO0r5prB2aYC+qIxUq+W\n9wBbMHMmSdJB2jNnG4Db0g9OKW+TwIZSpbag6I5kzeBMktSrX07KTj8gJ3BIU4PTAJYCq4vuSNYM\nziRJvWqd93MEsBwXA2hwRrachsGZJKkn9Wp5L3ArScbMxQAatJEtp2FwJknqR4Mkc2EZDQ3ayJbT\nMDiTJPWjOe/nkeltM2calJE9v6bBmSSpH80PyCemP82caVDMnEmSNI3mB6TBmQbNBQGSJE2jmTk7\nru22lKt6tbwD2I6ZM0mSDtKaKdtZr5a3F9YTjaMGBmeSJB1kcobr0iBMAkeWKrVlRXckSwZnkqR+\nNGa4Lg3CSC4KWJRn4yGEU4HzgIXABTHGd7Y9vhr4CPBgYDdwVozxJ53sK0kqXr1a3lmq1LYBqzBz\npsFrLadxQ5EdyVJumbMQwkLgfcCpwInA6SGEE9o2ex3wwxjjScCZwPld7CtJGg6Ntp/SoIxk5izP\nYc2TgRtijDfGGPcCFwHltm1OAL4BEGOMwMYQwtoO95UkDQeDMxVlJMtp5DmsOQHc3HJ7kvvq4DRd\nDTwX+HYI4WTggSQvcCf7SpKGw2TbT2lQmn9zZ5QqtdDhPj+qV8vnZd2RUqX2fODOerX8tX7byjM4\nm+pgm3cA54cQrgSuAa4E9ne4b6/PqeHncRwNHsfRMOdxPOd5j+FDX/gR/++vf6s2iA6pJyP5/3jx\n257FWW/9Knfv3vdI7juF2Jx23rPnPSuWL86sH1NTUyw+dCHHHNnVotEFMz2QZ3DW4L6ihKTXD/pW\nFWPcAZzVvB1C+AXwM2DZXPvOYMZfVPPGFB7HUeBxHA0dHcf3feaqBcDitauX35t/l9SDkf1/XL70\nUO7evW8lcHSHu5wLnHH6Gy55VL1a/nFW/Xj2q794NHDbzbfuvLtUqR1er5b7CobzDM6uAI4PIWwE\nNgGnAae3bhBCWAXsijHuCSG8DLgsxrgzhDDnvpKk4ZB+EBmYqRBp4eOOih+XKrXr06sbgMyCM+6b\n83YYsBLY1k9juS0IiDHuA84BLgWuBS6OMV4XQjg7hHB2utmJwDUhhOuBZwKvnG3fvPoqSZLGQl6r\nOydmuN6TXOucxRgvAS5pu++DLdcvB6adwDfdvpIkSX1orYuWpQ1t16/tpzHPECBJksbFvMicGZxJ\nkqRxkVddtPbMWV8MziRJ0lhIFw/swMyZJEnS0GiQT3C2p+V6XwzOJEnSOJkEjipVal1VjJ3DBuCn\nwD04rClJktSV5ryz9Vk0VqrUVgCrSIK+ScycSZIkdSXrchrNYKyRXtaUKrUl/TRocCZJksZJ1uU0\nmu00M2fQZ1bO4EySJI2TrMtpNNtpZs76bjvXMwRIkiQNmWZ2K4/M2aFZtG1wJkmSxknWmbPWOWeL\n2+7ricGZJEkaJ7cBe8kuc9YM8ia5LzjrK/BzzpkkSRob9Wr5ALCJbIc17wXuIKMhU4MzSZI0biaB\nY0uV2sIM2toANOrV8hSwBdiPmTNJkqSuNICFwDH9NFKq1A5N25gEqFfL+8kgK2dwJkmSxk1WiwLW\nAQta2mu2vb5UqfUcYxmcSZKkcZNVOY3WxQCtbS8C1vbaqMGZJEkaN1llzlrLaLS33XPgZ3AmSZLG\nTZ6Zs74DP4MzSZI0brI6v+Z0mbO+Az+DM0mSNG42pT/7HdZsPa8mbdfNnEmSJHWiXi3vIalJlkXm\n7ABwS8t9Zs4kSZJ60AA2lCq1BX20MQHcWq+W97bct6nlsZ4YnEmSpHE0CSwDjuhl5zSom+DgxQDU\nq+XdwFYc1pQkSepKv3PDjgKWcPB8s9a2e87KGZxJkqRx1O/csOnKaDQ1gMOAlb00bHAmSZLGUb/l\nNKYro9HUV+BncCZJksZRM4DqdVhzujIatN3XU9sGZ5IkaRxllTmbbljTzJkkSVKX+l0QMNuwZl+B\nn8GZJEkaO/VqeTuwg/4XBDisKUmSlJEG/WXO7qpXy3dP85jDmpIkST2YBI4sVWrLeth3A9PPNwPY\nBtyDmTNJkqSuNIcf13ezU6lSWwGsYvohTerV8hRJ4GbmTJIkqQu9ltOYbTEALY+tKVVqS7rtlMGZ\nJEkaV72uqpytjAZtj3WVlQODM0mSNL56XVXZaeasdduOGZxJkqRx1euqytnOq9nUczkNgzNJkjSu\n8syc9VxOw+BMkiSNq9uAvZg5kyRJKl69Wj4AbKK3zNm9wB2zbGPmTJIkqQeTwLpSpbawi30mgMm0\nntlMtgD7MXMmSZLUlQawEDimk41LldqhwDpmn29GvVreT5KVM3MmSZLUhW4L0a4DFjBHcJZqAOtL\nlUf1wzwAAA5eSURBVFpX8ZbBmSRJGmfd1iPrZDFAa9uLgLXddMjgTJIkjbNuV1V2UkajqadFAQZn\nkiRpnHUbQHWbOWvdpyMGZ5IkaZyZOZMkSRoim9KfnQZQnZz0vMnMmSRJUjfq1fIekppk3QxrHgBu\n6WDbnk5+bnAmSZLG3SSwoVSpLehg2wng1nq1vK+DbQ3OJEmSetAAlgFHzLZRGrxN0NmQJvVqeTdw\nOw5rSpIkdaXTuWFHAUvobDFAUzdZOcDgTJIkqdNVld2U0WhqAIcBKzvdweBMkiSNu04zZ92U0Wjq\nupzGoi4a71oI4VTgPJITil4QY3xn2+NHAx8nOU/VIuDdMcaPpo/9DXAGyYqIa4CXxBjvzbO/kiRp\nLHUaQHVTRqOpdVHAtZ3skFvmLISwEHgfcCpwInB6COGEts3OAa6MMT4GeBpQDSEsCiFsBF4GPC7G\n+CiS4O4FefVVkiSNtU5XVTYza91kzrqudZbnsObJwA0xxhtjjHuBi4By2zabuW8MdiVwe4xxH7Ad\n2AssDyEsApbT3QshSZLUqWYmbCiGNfMMziaAm1tuT3L/jv0j8IgQwibgauCVADHGO4AqcBNJ5d67\nYoxfz7GvkiRpTNWr5R3ADsYgczbVwTavA66KMa4HHgO8P4SwIoTwEOAvgY3AemBFCOGFHT6nl/l9\n8TiOxsXjOBoXj+NoXDyOHVw2rF1x+OHLD330bNs8YN3hzzhs2aHUq+Wdnbb7qf/zrGsAfuXEY86e\n5rhMK8/grAEc13L7OO4/ge4pwGcAYow/A34BnAA8HvhujLE5zPn5dNu5LPAy7y8ex9G4eBxH4+Jx\nHI2Lx7GDy+SWnV/fcc9eSpXa8pm2uemWHdvu3rX3x920e/r//vIhwD3/de2tV01zXKaVZ3B2BXB8\nCGFjCGExcBrwxbZtrgeeDhBCOAYIwM+ACDwphLAshLAg3aajFQ6SJEk9mHVRQKlSOwxYRZdz4OvV\n8hTTT+2aUW7BWZrxOge4lCSwujjGeF0I4ewQwtnpZm8HnhBCuBr4OvDaGOMdMcargQtJArwfpdt+\nKK++SpKksTfXxP1eymg0NYA1pUptSScb51rnLMZ4CXBJ230fbLm+FSjNsO+7gHfl2T9JkqTUXOU0\nelkM0N72epIpXLPyDAGSJElzl9PopYxGe9sdDW0anEmSJHWeOet1WLO1jVkZnEmSJM0dQJk5kyRJ\nGqDbSM5OlNeCADBzJkmS1Jl6tXyA5KxEMwVQG4B7gTt6aN7MmSRJUg8mgXWlSm26ahYTwGRat6xb\nW4D9GJxJkiR1pQEsBI5pvbNUqR0KrKO3+WbUq+X9wGYc1pQkSerKTMOP60hOudRTcNbS9vpSpTZn\n7GVwJkmSlJipnEY/ZTRa214ErJ1rQ4MzSZKkxEyrKvspo9HU8aIAgzNJkqTETAFUP2U0mjoup2Fw\nJkmSlJgpgOrnvJrtbZs5kyRJ6tCm9GcemTOHNSVJkrpRr5b3kNQkmy5zdgC4pY/mHdaUJEnqwSQw\nUarUFrTcNwHcUq+W9/XRrsOakiRJPWgAy4AjANIgbYL+5ptRr5Z3A7dj5kySJKkr7cOPRwFL6DM4\nS00CG9qycvdjcCZJknSf9on7WSwGaGoAhwErZ9vI4EySJOk+7ZmzLMpotLc967wzgzNJkqT75Jk5\n66ichsGZJEnSfQaROZt1UYDBmfT/27v3GLnKMo7j3y0FhIACqdxKQf6AJ1iLtHJRRKFYFdG2JhgU\n0FAMClGUKEK4eKt/oFRXLooRKbRQCXgNZcUECVU0MSCFggL1idwSSqEgLaRaxF7GP84Zd3ba7e7C\nDnvO8P0kzcw5550z78yTNr++75nzSpLUz5EzSZKkqujrnb0WWEt/gHLkTJIkaYw9RX+Amgi80Nc7\ne90onNeRM0mSpFdgBbDbzHMW70ARpEZjShPgRWAdjpxJkiSNSHP68UCKlQJGY0qTvt7ZjfJcjpxJ\nkiSNQHOk7PC27dE695u31sBwJkmSNFBzpOyItu3RPPegDGeSJEkDNUfKjmjbHs1zD8pwJkmSNFBz\ndGty2/ZonntQhjNJkqSBmgGqp217NDhyJkmSNELPAetbtkdzWtORM0mSpJHo6529CVhZbr4MrB7F\n0xvOJEmSXoHmaNmK8v5ko2UVsHFrDQxnkiRJm3uq7XFU9PXO3gg8vbU2hjNJkqTNrWh77MS5t8hw\nJkmStLmOjJwN55yGM0mSpM39o+1xND26tYPjO/CGkiRJdXcrMAu4rQPnnre1gz2Nxmj+AGFMNei/\nWZzqyzp2B+vYHaxjd7CONeO0piRJUoUYziRJkirEcCZJklQhhjNJkqQKMZxJkiRViOFMkiSpQgxn\nkiRJFWI4kyRJqhDDmSRJUoUYziRJkirEcCZJklQhhjNJkqQKMZxJkiRViOFMkiSpQgxnkiRJFTK+\nkyePiOOAy4BtgPmZeUnb8QnAT4E9y758LzMXlsd2AeYDk4EG8OnMvKuT/ZUkSRprHRs5i4htgB8C\nxwFvBU6KiIPamp0FLMvMQ4BjgN6IaAbGy4HfZuZBwMHA8k71VZIkqSo6OXJ2OPBIZj4BEBE3AbMZ\nGLKepgheAG8Ens/MDRHxJuA9mXkqQGZuAF7sYF8lSZIqoZPhbCLwZMv2CuCItjZXA0siYiWwM3Bi\nuX9/4LmIWAC8HbgXODsz13Wwv5IkSWOukz8IaAyjzYXA/Zm5N3AIcGVE7EwRGqcBP8rMacC/gfOH\nOFfPq+msKsM6dgfr2B2sY3ewjjXTyXD2FDCpZXsSxehZqyOBXwBk5qPA40CU7VZk5j1lu19ShDVJ\nkqSu1slwthQ4ICLeEhHbAR8Hbmlr83dgBkBE7EERzB7LzGeAJyPiwLLdDOChDvZVkiSpEjp2zVl5\nYf9ZwG0Ut9K4JjOXR8QZ5fGrgIuBBRHxAEVQPC8zV5en+AJwQxnsHgVO61RfJUmSqqKn0RjOpWGS\nJEl6LbhCgCRJUoUYziRJkirEcCZJklQhHV1b87Uy1BqeqqaIuBb4MPBsZk4p9+0G/AzYD3gCODEz\nXxizTmqrImIScD2wO8W9DX+SmVdYx3qJiDcAdwLbA9sBizPzAutYT+XyiUspbkk10zrWT+1Hzoa5\nhqeqaQFF3VqdD9yemQcCdzD0zYc1ttYDX8rMycA7gc+Xf/+sY41k5n+A6eU6xwcD0yPiKKxjXZ0N\nPEz/zeCtY83UPpzRsoZnZq4Hmmt4quIy80/Amrbds4DryufXAR99TTulEcnMZzLz/vL5vyjWzp2I\ndaydluXxtqOYhViDdaydiNgHOB6YT//KANaxZrohnG1pDc+JY9QXvXp7ZOaq8vkqYI+x7IyGLyLe\nAkwF7sY61k5EjIuI+ynq9fvMfAjrWEeXAucCm1r2Wcea6YZw5o3aulRmNrC+tRAROwG/As7OzLWt\nx6xjPWTmpnJacx/gvRExve24day4iPgIxTW8yxhkPU3rWA/dEM6Gs4an6mNVROwJEBF7Ac+OcX80\nhIjYliKYLcrMm8vd1rGmMvNF4FbgHVjHujkSmBURjwM3AsdGxCKsY+10Qzgbzhqeqo9bgFPL56cC\nN2+lrcZYRPQA1wAPZ+ZlLYesY41ExISI2KV8vgPwfmAZ1rFWMvPCzJyUmfsDnwCWZOansI610xXL\nN0XEh+i/lcY1mfntMe6ShiEibgSOBiZQXAfxdWAx8HNgX/zJd+WVv+j7I/BX+qdKLgD+gnWsjYiY\nQnGh+Ljyz6LM/G55CwbrWEMRcTRwTmbOso710xXhTJIkqVt0w7SmJElS1zCcSZIkVYjhTJIkqUIM\nZ5IkSRViOJMkSaoQw5kkSVKFGM4k1UJ5o+lNETGjbf8TEbFv2745EfHPiNi97fWPD/EeMyNi7hBt\n/lDeQ6p9/8KIOGF4n0aSBmc4k1Qn64Gry7U8mwa7WeNOwI9HcvLM7MvMbwzRbLD386aRkkbF+LHu\ngCSNwErgd0AvcMZW2jUo1vucEhEnZeaNrQfLcHclMJliZZFLMvOmiJgDHJ2Zp0XEMcAVwAbgLuCg\nzGwuBn56RPQCu1Is9v6bcv/HIuJCYFvgm5n564gYR7GCybFlvxZl5rzy/PMo/pP8ILAIuKRsswY4\nKTOffyVfkqR6c+RMUt18Bfhg+/TmFvwXOA24tHV6s/RVYGlmHkqxhNhFEbE/RTBqRMR4irB0cmZO\nK8/VHBnrAdaUr/0ixbJjzf3bA4cCxwFXRMQE4ExgIjAFOBw4ISKOL19zADA9M+cAFwFnZOZhQB8w\nbQTfiaQuYjiTVCuZuRb4DAOnN3vamvWUbe8F5lNMb7ZOO84AzoyIZcCdwI4Uo2jN104BVmXmg+W+\na1veo0H/wtEPU6wN29y/IDMbmbkSuBt4FzAdWFjufwm4AXhf2T7LzwPF4tQ3R8QPgOWZefvIvhlJ\n3cJwJql2yuByO/D9cte3ImJZ+WcmA4PYXIoRqlNa9o0DTsnMqZk5FXg3cFvL8Y0M/PexPfxtKB8b\nbcc2tr1mQ3me1jbj6L+k5KWWz3QZcAzwCDCvnB6V9DpkOJNUV+cAHwD2Br7WDFqZ2UdLGMrM9cAc\nimnDZmhbAnwOICL2ApYBk1petxzYNSLeVm6fDGwaoj89ZTsiYj/gMIrRsyXAqRExLiJ2LNssoS3w\nRcSfgZ0z83KKa9SmDvubkNRVDGeS6uT/I2It05tb+mFTo63tvcClLcfnAjtExN+AO4DzMvOx5uvK\nQPdJ4PqIWArsQ8so1yB9agAvR8R9FFOUn83M1cBVwArgAeA+YHFmLm7/PBTXwS0s3+90YKhfjUrq\nUj2Nhr/+lqRWEdEDfAeYm5nrIuLLwF6Zee4Yd03S64AjZ5LUJjMbwGrgnvJHA0cBF49tryS9Xjhy\nJkmSVCGOnEmSJFWI4UySJKlCDGeSJEkVYjiTJEmqEMOZJElShfwPJZTeny1B8bkAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107440390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of the various numbers of neighbors to use to build models\n",
    "# Create training and test sets\n",
    "# Iterate through that list and for each number of neighbors:\n",
    "#    Build a KNN model\n",
    "#    Evaluate it\n",
    "#    Record the score with the number of neighbors for that model\n",
    "# Plot results\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "n_neighbors = range(1, 51)\n",
    "\n",
    "scores = []\n",
    "for n in n_neighbors:\n",
    "    clf = KNeighborsClassifier(n)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))\n",
    "    \n",
    "knn_scores_df = pd.DataFrame(scores, columns=[\"Accuracy\"])\n",
    "ax = knn_scores_df.plot(figsize=(10,8), title=\"N-Neighbor Parameter Accuracy\")\n",
    "ax.set_xlabel(\"N-Neighbors\")\n",
    "ax.set_ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Do different train/test splits affect our score (accuracy)? How much do the scores vary each time you shuffle and split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)\n",
    "myknn = KNeighborsClassifier(2).fit(X_train,y_train)\n",
    "myknn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97368421052631582"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 1 75/25\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.25, random_state=0)\n",
    "myknn = KNeighborsClassifier(2).fit(X_train,y_train)\n",
    "myknn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89333333333333331"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2 50/50\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.50, random_state=0)\n",
    "myknn = KNeighborsClassifier(2).fit(X_train,y_train)\n",
    "myknn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88571428571428568"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 3 30/70\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.70, random_state=0)\n",
    "myknn = KNeighborsClassifier(2).fit(X_train,y_train)\n",
    "myknn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91111111111111109"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 4 90/10\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.90, random_state=0)\n",
    "myknn = KNeighborsClassifier(2).fit(X_train,y_train)\n",
    "myknn.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
